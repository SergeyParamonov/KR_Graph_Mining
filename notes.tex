\documentclass{article}
\usepackage{color}
\usepackage[usenames,dvipsnames]{xcolor}
\usepackage{listings}	
\usepackage{enumerate}
\usepackage{layouts}
\usepackage{times}
\usepackage[numbers]{natbib}
\usepackage{notoccite}
\usepackage{todonotes}
\usepackage{alltt}
\usepackage{url}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage{xspace}
\usepackage{tikz}
\usepackage[dvipsnames]{xcolor}

\usepackage{fancyvrb}

\theoremstyle{definition}
\newtheorem{definition}{Definition}[section]

% redefine \VerbatimInput
\RecustomVerbatimCommand{\VerbatimInput}{VerbatimInput}%
{fontsize=\footnotesize,
   %
  frame=lines,  % top and bottom rule only
  framesep=2em, % separation between frame and text
  rulecolor=\color{Gray},
      %
  label=\fbox{\color{Black}proB encoding},
  labelposition=topline,
        %
% commandchars=\|\(\), % escape character and argument delimiters for
                              % commands within the verbatim
% commentchar=*        % comment character
}

\author{Authors}
\title{Note on KR and Graph Mining}
\begin{document}
\maketitle

\section{Introduction}

Machine learning techniques often contain a process of learning certain patterns from a set of graphs.
This problem, which exists in many forms, is called the \emph{Graph Mining} problem.
\todo{Wat verantwoording en extra info vragen aan Sergey over waarom dit probleem interessant is. Ook is dit 'structured' graph mining, er bestaan andere vormen geloof ik, hoe bespreken we die?}

%\subsection{Problem definition}
\begin{definition}
Given a pair $\langle E_{+},E_{-}\rangle$ consisting of a set of \emph{positive} and \emph{negative} examples of \emph{labeled graphs}, respectively,
\emph{Graph mining} is the problem of finding one or more \emph{connected labeled graphs} $P$, called \emph{patterns},
that are \emph{homomorphic} with at least $N_{+}$ positive, and at most $N_{-}$ negative examples.
\end{definition}

\begin{definition}
\label{def:GM1}
A graph homomorphism $f$ between two labeled graphs $G = (V,E,L)$ and $G' = (V',E',L')$ is a mapping $V \rightarrow V'$ from vertices of $G$ to vertices of $G'$ s.t. 
\begin{itemize}
\item $\forall u,v \in V, \lbrace u,v\rbrace \in E \implies \lbrace f(u),f(v)\rbrace \in E'$ (the mapping preserves edges), and 
\item $\forall v \in V : L(v) = L(f(v))$ (the mapping respects labelings).
\end{itemize}
If there exists such a graph homomorphism between graphs $G$ and $G'$ we say $G$ is \emph{homomorphic} with $G'$.
\end{definition}


Furthermore, when looking for more than one pattern, one can impose restrictions on the different patterns that are found.
For example, it stands to reason that one wants only \emph{canonical} solutions, meaning that no two patterns found are \emph{isomorphic}.

\begin{definition}
A graph isomorphism $f$ between two labeled graphs $G = (V,E,L)$ and $G' = (V',E',L')$ is a \emph{one-to-one} mapping $V \rightarrow V'$ 
such that $f$ represents a homomorphism from $G$ to $G'$,
and its inverse $f^{-1}$ represents a homomorphism from $G'$ to $G$.
If there exists such a graph isomorphism between $G$ and $G'$ we say $G$ ($G'$) is \emph{isomorphic} with $G'$ ($G$)
\end{definition}


\begin{definition}
Let $\mathcal{G}$ be a class of graphs, closed under isomorphism.
A function $c$ for which $\forall G,H \in \mathcal{G} : G \simeq H \iff c(G) = c(H)$ and $\forall G \in \mathcal{G} : G \simeq c(G)$ hold, is called a \emph{canonization}.
The graph $c(G)$ is called the \emph{canonical form} w.r.t $c$, and is denoted by $\mathit{canon}(G)$.
\end{definition}
%Only the first restriction should correspond to 'complete invariant'.

An attempt to model the Graph Mining problem in both IDP as well as ProB makes it clear
that neither language allows us to express the problem to its full extent.
We now try to link the shortcomings of each language to the expressiveness of the underlying logic on which they are built.

First we introduce a new definition of the graph mining problem, equivalent to \textbf{Def.}~\ref{def:GM1}.
We'll assume a sufficiently large supply of vertices, and represent example graphs directly as a triple $\langle Edge, Label, Class\rangle$, consisting of an edge relation and a labeling function over the vertices, as well as a classification (positive/negative).

\begin{definition} \textbf{Graph Mining (redefined)}
Given a supply of vertices $V$ and a set of $\langle E, L, C\rangle$ triples,
where $E$ and $L$ represent the edge relation and labeling function over a supply of vertices respectively,
%which consist of an edge relation, 
we look for a graph $\langle E_{p}, L_{p}\rangle$ such that
for at least $N_{+}$ of the triples $\langle E, L, C\rangle$ with $C=Pos$, and for at most $N_{-}$ of such triples with $C=Neg$, there exists a function $f$ s.t. $\forall u,v \in V, \lbrace u,v\rbrace \in E_{p} \implies \lbrace f(u),f(v)\rbrace \in E'$ and $\forall v \in V : L_{p}(v) = L(f(v))$.
\end{definition}


%Furthermore, we 

\subsection{IDP}
The IDP language can express \emph{Existential Second Order} problems; problems in which there is an existentially quantified, generally second order, vocabulary of symbols and a first order theory with symbols from that vocabulary.

This restriction to \emph{Existential} Second Order forces us 
%to separate the constraint describing the positive homomorphic property, and the constraint on its number of occurrences.
%This, from a KR point of view, 
%Furthermore, the restriction to ESO requires us 
to use a Skolemization based trick when expressing the homomorphic property.
We introduce a general function \verb|f| that represents the homomorphisms, and make its dependency on a specific goal graph explicit using an additional argument:
\verb|partial f(graph, t_var):node|.
In Second Order Logic, this dependency would follow directly from the order of the separate quantifications.
We can now use this \verb|f| anywhere we would the regular homomorphic function for a specific graph by fixing the goal graph.
Note that this encoding also requires us to make this function \verb|f| partial, as the Graph Mining problem does not require the solution to be homomorphic with \emph{all} goal graphs.
\todo{Of course, other (even uglier) schemes exist to encode this. Should we mention this?}

Furthermore, limiting ourselves to existential second order prohibits us from expressing the constraint negative constraint on homomorphism (No more than $N_{-}$ negative examples are homomorphic) in the same model.
In fact, the negative constraint asserts a property for all candidate homomorphic functions, which would lead to \emph{universal} quantification.
Therefore, our only recourse is to encode the positive constraint and require it to fail when queried.

Beyond the Existential Second Order restriction, the IDP language is also extended with inductive definitions. These definitions, evaluated under the well-founded semantics, allows the derivation of negative knowledge that otherwise would be underivable.
\reversemarginpar
\todo{A section about inductive definitions, and their use. (Being able to derive negative knowledge)}

\subsection{Eventual encoding}
\begin{alltt}
//Homomorphism/2 is a higher-order predicate:
//Edge1 and Edge2 are predicates themselves.
homomorphism(Edge1, Edge2) \(\iff \exists\) f: (\(\forall\) x, y : x \(\neq\) y \(\Rightarrow\) f(x) \(\neq\) f(y)) \(\wedge\)
    (\(\forall\)x, y : Edge1(x, y) \(\implies\) Edge2(f (x), f (y)))

\textbraceleft
    reachable(x,y,Edge) \(\leftarrow\) Edge(x,y) \(\lor\) Edge(y,x).
    reachable(x,y,Edge) \(\leftarrow \exists\) : reachable(x,z,Edge) \(\wedge\) reachable(z,y,Edge).
\textbraceright

isomorph(Edge1,Edge2) \(\iff \exists\)f : (\(\forall\) x,y:Edge1(x,y) \(\iff\) Edge2(f(x),f(y))) \(\wedge\)
    (\(\forall\)x,y:x\(\neq\)y\(\implies\)f(x)\(\neq\)f(y)).

//\(\forall\)Pat represents quantification over a predicate Pat/2. 
//A pattern is represented by its Edge relation. 
\(\forall\)P : pattern(P) \(\implies\) P(x,y) \(\iff\) Template(x,y) .
\(\forall\)P : pattern(P) \(\implies\) #\textbraceleft Pos : positive(Pos) \(\wedge\) homomorphism(P, Pos) \textbraceright \(\geq\) \(N{+}\).
\(\forall\)P : pattern(P) \(\implies\) #\textbraceleft Neg : negative(Neg) \(\wedge\) homomorphism(P, Neg) \textbraceright \(\leq\) \(N_\).
\(\forall\)P,P2 :pattern(P)\(\wedge\)pattern(P2)\(\wedge\)P\(\neq\)P2 \(\iff\) \(\neg\)isomorph(P,P2).

\end{alltt}
\reversemarginpar
\todo{Tekstuele uitleg hierbij}

\subsection{ProB}

\section{Feature Comparison}

\subsection{IDP} 

\textbf{Pro:}
\begin{itemize}
  \item can model inductive definitions
  \item allows core formulation in a high-level language (NP)
  \item handles aggregates
  \item has support for variety of constraints
\end{itemize}
\textbf{Cons:}
\begin{itemize}
  \item cannot handle negative case $\textit{NP}^\textit{NP}$ complexity
  \item cannot model subgraph isomorphism independence
  \item cannot handle dominance, i.e., when one model is preferred over another 
\end{itemize}

\paragraph{ASP}
Mostly the same but in theory can handle $\textit{NP}^\textit{NP}$, in practice however, it would require encoding tricks and unavoidably lead to the same problem as in IDP -- indexing homomorphism enumeration.

\subsection{proB}
\textbf{Pro:}
\begin{itemize}
  \item can model negative case
  \item can model subgraph isomorphism independence
\end{itemize}
\textbf{Cons:}
\begin{itemize}
  \item cannot handle inductive definitions
  \item cannot handle different types of aggregates (? needs to be checked again)
\end{itemize}

the rest of constraints? 

\section{Code in ProB and IDP}

\VerbatimInput{original_prob_files/PositiveAndNegative.mch}
\pagebreak

\VerbatimInput[label=IDP encoding]{IDPencoding/core_constraints.idp}



\end{document}
